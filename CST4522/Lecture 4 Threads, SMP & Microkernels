Every process has it's own address space to hold process image (data about process etc)
Processes follow an execution path
These two characterisitics are treated independently by the operating system.

Unit of Dispatching ---> Thread/Lightweight process (what is executed by the processor, sequence of instructions, smallest unit of execution)
Unit of Resource ownership ---> Process/Task (What owns the resource)

Processes have states, priority etc.

The processor runs a thread (that's why it's called a unit of dispatching), so when there is an app, it should have a process, 
which must have atleast one thread called primary thread. (If a process has ZERO threads, then the process cannot exist)

There can be multiple threads in a process also, called multithreading.

A thread always belongs to a process (cannot exist outside a process)


UNIX can only do multiple processes, not multithreading, but windows can do multiprocesses that have multiple threads. (check figure 4.1 and 4.2 if confused, lecture 4)

In fig 4.2, user address space is where the process resides, threads share the resources of the process (occupies the same address space, and shares all other resources like IO, files etc.
In fig 4.2, multiple thread control blocks are needed, because sometimes if one thread might be running, but another might want to be used. 

At any point of time, a thread can have:
-an execution state (ready, running, block etc)
-has an execution stack (because threads share the resources of the process)

Browsers use multithreading (let's say each tab is another thread), spreadsheet application (one thread can be used for user input, another can be used for commands, third thread is for displaying menu)

Multithreading improves responsiveness

Web servers are designed as multithreaded, so each client can be handled individually, immediately, independently. 



Benefits of Threads:
Faster to switch between threads compared to process
faster to terminate threads
faster to make new threads also


Use of Threads in a single-user Multiprocessing System:
Increases percieved speed of application                             note: if you have 1 core, and an app that is multithreaded. the CPU switches between threads, at the process level it schedules the threads within the processes, 
                                                                            along with priority scheduling of the processes itself 

When you suspend a process, it suspends all threads within the process. 
When you kill a process, it kills all threads within the process.


Thread States
Spawn (new process -> new thread)
Block 
Unblock 
Finish


Remote Procedure Call (RPC):
Remote Comms protocol to request service in program located in another system (calling functions in one code from another code or library or class basically)
Procedures have to exist is two different address spaces (can be on same host or two different hosts)

RPC using Threads: 
(Uni Processors Example)
Figure 4.3 a, One Primary thread using RPC, you can also make it two threads handling the two requests at the same time. Speeds up the application. (becomes fig4.3 b)
In Figure 4.3 b, both threads are in blocked state, Processor switches to first thread, runs for a bit, then blocks so the second thread can complete, then unblocks to run the primary thread, finishing the full task.
It does all that because it's a uniproc, so it has to balance the resources between the two threads. If it was a multiprocessor, it could run both threads simultaneously 


User-Level Threads:
Managed by user-level libraries or APIs (like python, java have their own functions for multithreading)
All tasks of THREAD managements is done by user libraries, the OS just makes the processes. Kernel doesn't know about the threads that exist, 
Limitations of ULT approach can be:
If kernet doesn't know about the threads, there is no real benefit for making the threads from the kernel's side. It depends on what kind of scheduling is used by the developer.
If one thread is ready or blocked, the entire process is made ready or blocked, even if other threads in the process are not ready or not blocked.

Kernel-Level Threads:
THe kernel recognizes the threads, you just need an APi for the kernel threading stuff.
With KLT approach, the limitations of ULT are dealt with. Also if the kernel can schedule two threads, on two different processes (on a multitprocessor)

Combined Approach:
Both ULT and KLT are used.                                                                               (DOUBT so what's the point of ULT if it's just completely worse than KLT? Why have a conbined approach at all?
Figure 4.6                                                                                                It's because in the start, ULT was all there was, many OS didn't have Kernel Level multithreading. 
                                                                                                          Nowadays, it's mostly just the combined approach anyway.
                                                                                                          It still exists incase the system or OS doesn't support kernel level, sort of like a legacy thing. Maybe some embedded or low power systems use it?)




Categories of Computer Systems:
it's a framework, aka FLynn's Taxonomy (gives idea of how computer architecture has evolved based on the instruction prcessing capabilities of the systems)

4 Main Models:
SISD (traditional, sequential processing/computing)
SIMD (Parallel computing, each unit executes same instructions on multiple data points 
      eg vector processing, array of elements A, another array of element B, performing addition of the elements in both arrays
      used in GPUs also? apparently multiple sets of SIMD 
MISD (used when security and reliability is needed)
MIMD (used in parallel architectures, most popular)
next page for diagram of all 4 types.

Multiprocessor Operating System Design Considerations:
There should be proper load balancing 


MicroKernels and Monolithic Kernels:
Monolithic kernels have all the features, microkernels have barebone features, enough for the system to run. Microkernels itself are very small. 
Monolithic kernels are faster, because in microkernels there's an extra layer of communication between the different features that the microkernel doesn't include. 
But microkernels are most modular, saving on space for embedded systems etc.



Windows Thread States:
Ready        }
Standby      } Running
Running      }

Waiting      }
Transition   }Not Runnable
Terminated   }


Case Study: Oracle Solaris
Uses Three Level Thread management structure (it's how it implements threads)
ULT, KLT, LightWeightProcess (LWP) inbetween those two [figure 4.15]





Do Lecture 4 MCQ on MyMDX



















